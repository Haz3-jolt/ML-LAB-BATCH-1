{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f07408",
   "metadata": {},
   "source": [
    "# Single Perceptron ANN for Iris Dataset\n",
    "\n",
    "This notebook implements a simple single perceptron artificial neural network to classify iris flowers.\n",
    "\n",
    "## Perceptron Overview:\n",
    "- **Single layer neural network** with one output neuron\n",
    "- Uses **linear activation** with step function for binary classification\n",
    "- Can only solve **linearly separable** problems\n",
    "- Simple learning algorithm that updates weights based on errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c65b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the iris dataset\n",
    "def load_iris_data():\n",
    "    \"\"\"Load iris dataset for binary classification (Setosa vs Others)\"\"\"\n",
    "    iris = load_iris()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['species'] = iris.target_names[iris.target]\n",
    "    \n",
    "    # Convert to binary classification: Setosa (1) vs Others (0)\n",
    "    df['is_setosa'] = (iris.target == 0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "iris_df = load_iris_data()\n",
    "print(\"Iris Dataset Shape:\", iris_df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(iris_df.head())\n",
    "print(\"\\nBinary classification target distribution:\")\n",
    "print(\"Setosa (1):\", sum(iris_df['is_setosa'] == 1))\n",
    "print(\"Others (0):\", sum(iris_df['is_setosa'] == 0))\n",
    "print(\"\\nOriginal species distribution:\")\n",
    "print(iris_df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Single Perceptron Implementation\n",
    "class SinglePerceptron:\n",
    "    \"\"\"Simple Single Perceptron for binary classification\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, max_epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.training_errors = []\n",
    "    \n",
    "    def activation_function(self, x):\n",
    "        \"\"\"Step function: returns 1 if x >= 0, else 0\"\"\"\n",
    "        return 1 if x >= 0 else 0\n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        \"\"\"Predict for a single sample\"\"\"\n",
    "        # Calculate weighted sum + bias\n",
    "        weighted_sum = np.dot(self.weights, x) + self.bias\n",
    "        # Apply step function\n",
    "        return self.activation_function(weighted_sum)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the perceptron\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize weights and bias randomly (small values)\n",
    "        self.weights = np.random.uniform(-0.1, 0.1, n_features)\n",
    "        self.bias = np.random.uniform(-0.1, 0.1)\n",
    "        \n",
    "        print(f\"Initial weights: {self.weights}\")\n",
    "        print(f\"Initial bias: {self.bias:.4f}\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(self.max_epochs):\n",
    "            errors = 0\n",
    "            \n",
    "            # Process each training sample\n",
    "            for i in range(n_samples):\n",
    "                # Forward pass\n",
    "                prediction = self.predict_single(X[i])\n",
    "                \n",
    "                # Calculate error\n",
    "                error = y[i] - prediction\n",
    "                \n",
    "                # Update weights and bias if there's an error\n",
    "                if error != 0:\n",
    "                    self.weights += self.learning_rate * error * X[i]\n",
    "                    self.bias += self.learning_rate * error\n",
    "                    errors += 1\n",
    "            \n",
    "            self.training_errors.append(errors)\n",
    "            \n",
    "            # Print progress every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}: {errors} errors\")\n",
    "            \n",
    "            # Early stopping if no errors\n",
    "            if errors == 0:\n",
    "                print(f\"\\\\nConverged at epoch {epoch + 1}!\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\\\nFinal weights: {self.weights}\")\n",
    "        print(f\"Final bias: {self.bias:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict for multiple samples\"\"\"\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            pred = self.predict_single(X[i])\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def get_decision_boundary_params(self):\n",
    "        \"\"\"Get parameters for plotting decision boundary (for 2D visualization)\"\"\"\n",
    "        if len(self.weights) >= 2:\n",
    "            # For 2D: w1*x1 + w2*x2 + b = 0\n",
    "            # Solve for x2: x2 = -(w1*x1 + b) / w2\n",
    "            w1, w2 = self.weights[0], self.weights[1]\n",
    "            return w1, w2, self.bias\n",
    "        return None\n",
    "\n",
    "print(\"Single Perceptron class implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X = iris_df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "y = iris_df['is_setosa']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize the features (important for perceptron)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\\\nTraining set target distribution:\")\n",
    "print(f\"Setosa: {sum(y_train)}, Others: {len(y_train) - sum(y_train)}\")\n",
    "print(f\"\\\\nTest set target distribution:\")\n",
    "print(f\"Setosa: {sum(y_test)}, Others: {len(y_test) - sum(y_test)}\")\n",
    "print(f\"\\\\nFeatures: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Single Perceptron\n",
    "print(\"Training Single Perceptron...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create and train the perceptron\n",
    "perceptron = SinglePerceptron(learning_rate=0.1, max_epochs=100)\n",
    "perceptron.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "print(\"\\\\nTraining completed!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate\n",
    "print(\"Making predictions...\")\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = perceptron.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = perceptron.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\\\nPerformance Results:\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Others', 'Setosa']))\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"SAMPLE PREDICTIONS:\")\n",
    "print(\"=\"*50)\n",
    "for i in range(min(10, len(X_test))):\n",
    "    actual = y_test.iloc[i]\n",
    "    predicted = y_test_pred[i]\n",
    "    features = X_test.iloc[i]\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Features: Sepal L={features[0]:.2f}, Sepal W={features[1]:.2f}, Petal L={features[2]:.2f}, Petal W={features[3]:.2f}\")\n",
    "    print(f\"  Actual: {'Setosa' if actual == 1 else 'Others'}, Predicted: {'Setosa' if predicted == 1 else 'Others'}\")\n",
    "    print(f\"  {'✓ Correct' if actual == predicted else '✗ Wrong'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbde872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Training Error Over Epochs\n",
    "axes[0,0].plot(range(1, len(perceptron.training_errors) + 1), perceptron.training_errors, 'b-o', markersize=4)\n",
    "axes[0,0].set_title('Training Errors Over Epochs')\n",
    "axes[0,0].set_xlabel('Epoch')\n",
    "axes[0,0].set_ylabel('Number of Errors')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Others', 'Setosa'], yticklabels=['Others', 'Setosa'],\n",
    "            ax=axes[0,1])\n",
    "axes[0,1].set_title('Confusion Matrix')\n",
    "axes[0,1].set_xlabel('Predicted')\n",
    "axes[0,1].set_ylabel('Actual')\n",
    "\n",
    "# 3. Decision Boundary (using first 2 features for visualization)\n",
    "X_2d = X_train_scaled[:, :2]  # Use first 2 features\n",
    "y_2d = y_train.values\n",
    "\n",
    "# Train a simple 2D perceptron for visualization\n",
    "perceptron_2d = SinglePerceptron(learning_rate=0.1, max_epochs=100)\n",
    "perceptron_2d.fit(X_2d, y_2d)\n",
    "\n",
    "# Create mesh grid\n",
    "h = 0.02\n",
    "x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Make predictions on mesh grid\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = perceptron_2d.predict(mesh_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "axes[1,0].contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "# Plot training points\n",
    "setosa_mask = y_2d == 1\n",
    "others_mask = y_2d == 0\n",
    "\n",
    "axes[1,0].scatter(X_2d[setosa_mask, 0], X_2d[setosa_mask, 1], \n",
    "                 c='red', marker='o', label='Setosa', s=50)\n",
    "axes[1,0].scatter(X_2d[others_mask, 0], X_2d[others_mask, 1], \n",
    "                 c='blue', marker='s', label='Others', s=50)\n",
    "\n",
    "axes[1,0].set_xlabel('Sepal Length (standardized)')\n",
    "axes[1,0].set_ylabel('Sepal Width (standardized)')\n",
    "axes[1,0].set_title('Decision Boundary (2D Projection)')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Model Summary and Weights\n",
    "weights_text = f\"\"\"Perceptron Model Summary:\n",
    "\n",
    "Final Weights:\n",
    "• Sepal Length: {perceptron.weights[0]:.4f}\n",
    "• Sepal Width:  {perceptron.weights[1]:.4f}\n",
    "• Petal Length: {perceptron.weights[2]:.4f}\n",
    "• Petal Width:  {perceptron.weights[3]:.4f}\n",
    "• Bias:         {perceptron.bias:.4f}\n",
    "\n",
    "Performance:\n",
    "• Training Accuracy: {train_accuracy:.4f}\n",
    "• Test Accuracy:     {test_accuracy:.4f}\n",
    "• Epochs to converge: {len(perceptron.training_errors)}\n",
    "\n",
    "Model Characteristics:\n",
    "• Linear classifier only\n",
    "• Can solve linearly separable problems\n",
    "• Simple learning algorithm\n",
    "• Fast training\"\"\"\n",
    "\n",
    "axes[1,1].text(0.05, 0.95, weights_text, transform=axes[1,1].transAxes, \n",
    "               verticalalignment='top', fontsize=10, fontfamily='monospace',\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "axes[1,1].set_title('Model Summary')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nFinal Results Summary:\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"Model: Single Perceptron ANN\")\n",
    "print(f\"Problem: Binary Classification (Setosa vs Others)\")\n",
    "print(f\"Features: 4 iris measurements (standardized)\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Epochs to converge: {len(perceptron.training_errors)}\")\n",
    "print(f\"Final weights: {perceptron.weights.round(4)}\")\n",
    "print(f\"Final bias: {perceptron.bias:.4f}\")\n",
    "print(\"✓ Single Perceptron implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
